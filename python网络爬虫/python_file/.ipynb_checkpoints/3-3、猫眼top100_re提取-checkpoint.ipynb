{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "class Maoyan(object):\n",
    "    def __init__(self):\n",
    "        self.url = \"https://maoyan.com/board/4?offset={}\"\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36\",\n",
    "            \"Cookie\": \"__mta=44373403.1568707842875.1568707937069.1568707995099.9; _lxsdk_cuid=16d2d2561931-0a31202ebc6845-79475878-3c000-16d2d256194c8; uuid_n_v=v1; uuid=A5005A50D92211E9AFA53B88E9213B3C5B1D8699CC9F4F899C7C340A5AFA8E88; _csrf=5519df7f94e06e9680b6943b869454f49d6321b2949bf4a570f45f49d1351e4c; _lx_utm=utm_source%3DBaidu%26utm_medium%3Dorganic; _lxsdk=A5005A50D92211E9AFA53B88E9213B3C5B1D8699CC9F4F899C7C340A5AFA8E88; __mta=44373403.1568707842875.1568707844633.1568707867388.3; _lxsdk_s=16d3e4612f3-d9a-f82-3b2%7C%7C26\"\n",
    "        }\n",
    "        \n",
    "    def parse_url(self, url):\n",
    "        print(url)\n",
    "        r = requests.get(url, headers=self.headers)\n",
    "        if r.status_code == 200:\n",
    "            return r.text\n",
    "        return None\n",
    "    \n",
    "    def get_data(self, html):\n",
    "        \"\"\"\n",
    "        获取电影数据\n",
    "        返回：电影名， 明星， 发行时间， 链接地址(文件在服务器的相对位置)\n",
    "        \"\"\"\n",
    "        # 获取电影名\n",
    "        p_film_name = re.compile(r'<p.*?><a.*?films.*?title=\\\"(.*?)\\\".*?</a>', re.S)\n",
    "        film_name = re.findall(p_film_name, html)\n",
    "        \n",
    "        # 获取表演明星\n",
    "        p_star = re.compile(r'<p class=\"star\">\\s+(.*?)\\s+</p>', re.S)\n",
    "        star = re.findall(p_star, html)\n",
    "        \n",
    "        # 获取上映时间\n",
    "        p_releasetime = re.compile(r'<p class=\"releasetime\">上映时间：(.*?)</p>')\n",
    "        releasetime = re.findall(p_releasetime, html)\n",
    "        \n",
    "        # 获取链接\n",
    "        p_href = re.compile(r'<p.*?><a href=\"(.*?)\" title', re.S)\n",
    "        href = re.findall(p_href, html)\n",
    "        return film_name, star, releasetime, href\n",
    "                                 \n",
    "    def save_data(self, movie_data):\n",
    "        film_name, star, releasetime, href = movie_data\n",
    "        movie_info = []\n",
    "        for i in range(len(film_name)):\n",
    "            item = {}\n",
    "            item['film_name'] = film_name[i]\n",
    "            item['star'] = star[i]\n",
    "            item[\"releasetime\"] = releasetime[i]\n",
    "            item['href'] = \"https://maoyan.com\" + href[i]\n",
    "            movie_info.append(item)\n",
    "        with open(\"../crawl_file/3-3.maoyan_top100.txt\", 'a+', encoding='utf-8') as f:\n",
    "\n",
    "            for i in range(len(film_name)):\n",
    "                item = {}\n",
    "                item['film_name'] = film_name[i]\n",
    "                item['star'] = star[i]\n",
    "                item[\"releasetime\"] = releasetime[i]\n",
    "                item['href'] = \"https://maoyan.com\" + href[i]\n",
    "                f.write(json.dumps(item, ensure_ascii=False))\n",
    "                f.write('\\n')\n",
    "        print('保存成功')\n",
    "                       \n",
    "            \n",
    "    def run(self):\n",
    "        \"\"\"实现主程序\"\"\"\n",
    "        # 1.设置url 连接页码，并获取url\n",
    "        current_page = 0\n",
    "        while True:\n",
    "            url = self.url.format(current_page)\n",
    "            # 2.发送请求，获取数据\n",
    "            html = self.parse_url(url)\n",
    "            # 3。提取数据\n",
    "            movie_data = self.get_data(html)\n",
    "            # 4.保存数据\n",
    "            self.save_data(movie_data)\n",
    "            # 设置退出条件\n",
    "            if (len(movie_data[0]) < 10) or (current_page == 90):\n",
    "                break\n",
    "            # 5.构造下一个url\n",
    "            current_page += 10\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://maoyan.com/board/4?offset=0\n",
      "保存成功\n",
      "https://maoyan.com/board/4?offset=10\n",
      "保存成功\n",
      "https://maoyan.com/board/4?offset=20\n",
      "保存成功\n",
      "https://maoyan.com/board/4?offset=30\n",
      "保存成功\n",
      "https://maoyan.com/board/4?offset=40\n",
      "保存成功\n",
      "https://maoyan.com/board/4?offset=50\n",
      "保存成功\n",
      "https://maoyan.com/board/4?offset=60\n",
      "保存成功\n",
      "https://maoyan.com/board/4?offset=70\n",
      "保存成功\n",
      "https://maoyan.com/board/4?offset=80\n",
      "保存成功\n",
      "https://maoyan.com/board/4?offset=90\n",
      "保存成功\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    maoyan = Maoyan()\n",
    "    movie_data = maoyan.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "def get_one_page(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.162 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        return None\n",
    "    except RequestException:\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_one_page(html):\n",
    "    pattern = re.compile('<dd>.*?board-index.*?>(\\d+)</i>.*?data-src=\"(.*?)\".*?name\"><a'\n",
    "                         + '.*?>(.*?)</a>.*?star\">(.*?)</p>.*?releasetime\">(.*?)</p>'\n",
    "                         + '.*?integer\">(.*?)</i>.*?fraction\">(.*?)</i>.*?</dd>', re.S)\n",
    "    items = re.findall(pattern, html)\n",
    "    for item in items:\n",
    "        yield {\n",
    "            'index': item[0],\n",
    "            'image': item[1],\n",
    "            'title': item[2],\n",
    "            'actor': item[3].strip()[3:],\n",
    "            'time': item[4].strip()[5:],\n",
    "            'score': item[5] + item[6]\n",
    "        }\n",
    "\n",
    "\n",
    "def write_to_file(content):\n",
    "    with open('result.txt', 'a', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(content, ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "def main(offset):\n",
    "    url = 'http://maoyan.com/board/4?offset=' + str(offset)\n",
    "    html = get_one_page(url)\n",
    "    for item in parse_one_page(html):\n",
    "        print(item)\n",
    "        write_to_file(item)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for i in range(10):\n",
    "        main(offset=i * 10)\n",
    "        time.sleep(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
